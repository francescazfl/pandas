{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zUORCRJ0rWk"
   },
   "source": [
    "Team: Pandas\n",
    "\n",
    "Group members: Francesca-Zhoufan Li, Elena Sorina Lupu, Nikhil Ranganathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APtDm7e_0Thi"
   },
   "source": [
    "# Install and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FotGkO3m0be7",
    "outputId": "9c6757a6-37b4-4ef8-edf7-d7bcb2d36f44"
   },
   "outputs": [],
   "source": [
    "!pip install iqplot\n",
    "!pip install surprise\n",
    "!pip install nevergrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "pQ1za8T7z6-P",
    "outputId": "6f54666e-1d2e-40b8-eb69-c1a48ae89171"
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"white\", context=\"talk\")\n",
    "\n",
    "import iqplot\n",
    "import bokeh.io\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import column, gridplot\n",
    "from bokeh.models import (\n",
    "    ColorBar,\n",
    "    ColorMapper,\n",
    "    LinearColorMapper,\n",
    "    Ticker,\n",
    "    ColumnDataSource, \n",
    "    Label, \n",
    "    LabelSet\n",
    ")\n",
    "\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import dim\n",
    "from holoviews import opts\n",
    "\n",
    "# import bebi103\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import surprise\n",
    "from surprise import SVD, Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "import nevergrad as ng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfntsu9C0jBs"
   },
   "source": [
    "# Load and Clean Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQM6pMvfFSJU"
   },
   "outputs": [],
   "source": [
    "def load_train_test(trainortest):\n",
    "    \"\"\"Load train or test data\"\"\"\n",
    "    return pd.read_csv(\n",
    "        \"https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project2/data/\"\n",
    "        + trainortest,\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\"USER\", \"MOVIE\", \"RATING\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ruPr8Y5z6-V"
   },
   "outputs": [],
   "source": [
    "def load_data(f_data, f_train, f_test, f_movies):\n",
    "    \"\"\"Load the user and movie data, FZL modified\"\"\"\n",
    "\n",
    "    data = load_train_test(f_data)\n",
    "    train = load_train_test(f_train)\n",
    "    test = load_train_test(f_test)\n",
    "\n",
    "    movies = pd.read_csv(\n",
    "        \"https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/projects/project2/data/\"\n",
    "        + f_movies,\n",
    "        encoding=\"latin-1\",\n",
    "        sep=\"\\t\",\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"MOVIE_ID\",\n",
    "            \"TITLE\",\n",
    "            \"UNKNOWN\",\n",
    "            \"ACTION\",\n",
    "            \"ADVENTURE\",\n",
    "            \"ANIMATION\",\n",
    "            \"CHILDREN\",\n",
    "            \"COMEDY\",\n",
    "            \"CRIME\",\n",
    "            \"DOCUMENTARY\",\n",
    "            \"DRAMA\",\n",
    "            \"FANTASY\",\n",
    "            \"FILM-NOIR\",\n",
    "            \"HORROR\",\n",
    "            \"MUSICAL\",\n",
    "            \"MYSTERY\",\n",
    "            \"ROMANCE\",\n",
    "            \"SCI-FI\",\n",
    "            \"THRILLER\",\n",
    "            \"WAR\",\n",
    "            \"WESTERN\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    movies.loc[movies.TITLE == \"unknown\", \"TITLE\"] = \"MOVIE_ID: \" + movies.loc[\n",
    "        movies.TITLE == \"unknown\", \"MOVIE_ID\"\n",
    "    ].astype(\"str\")\n",
    "\n",
    "    return data, train, test, movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pa0D7dO4FSJW"
   },
   "outputs": [],
   "source": [
    "def check_dup(df, df_details):\n",
    "    \"\"\"Check fi there are duplicated entries for each dataframe\"\"\"\n",
    "    print(f\"There are {sum((df.duplicated())*1)} duplicate entires in {df_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Z6i5VL2z6-V",
    "outputId": "85823e10-6f92-45cd-dac4-579699c14287"
   },
   "outputs": [],
   "source": [
    "data, Y_train_df, Y_test_df, movies = load_data(\n",
    "    \"data.txt\", \"train.txt\", \"test.txt\", \"movies.txt\"\n",
    ")\n",
    "\n",
    "check_dup(Y_train_df, \"Y_train_df\")\n",
    "check_dup(Y_test_df, \"Y_test_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY6T8AJdz6-W"
   },
   "source": [
    "# Basic Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1Yri7-4z6-W"
   },
   "source": [
    "## All MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "1xoyZS6Fz6-W",
    "outputId": "e625b1c6-aec5-477f-c3f4-17ed115ce0dd"
   },
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame(movies.set_index([\"MOVIE_ID\", \"TITLE\"]).sum(axis=0)).reset_index()\n",
    "sum_df.columns = [\"Genres\", \"Counts\"]\n",
    "sum_df = sum_df.sort_values([\"Counts\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "x = np.array(list(sum_df.Genres))\n",
    "y1 = sum_df.Counts.values\n",
    "sum_bar = sns.barplot(x=x, y=y1, palette=\"crest_r\")\n",
    "\n",
    "for index, row in sum_df.iterrows():\n",
    "    sum_bar.text(index, row.Counts, row.Counts, color=\"black\", ha=\"center\")\n",
    "\n",
    "sum_bar.set(xlabel=\"Genres\", ylabel=\"Counts\", title=\"Summary of gernre counts\")\n",
    "sum_bar.set_xticklabels(sum_bar.get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tK8dd0YLJlWX"
   },
   "outputs": [],
   "source": [
    "def plot_genre_heat(df, title_details):\n",
    "    \"\"\"Plot heatmap based on if belonging to the genre\"\"\"\n",
    "    plt.figure(figsize=(10, len(df)*0.02))\n",
    "    movie_heat = sns.heatmap(\n",
    "        df,\n",
    "        yticklabels=False,\n",
    "        cmap=[(1, 1, 1), (0.14573579, 0.29354139, 0.49847009)],\n",
    "        cbar_kws=dict(\n",
    "            use_gridspec=False,\n",
    "            shrink=0.2,\n",
    "            ticks=[0, 1],\n",
    "            label=\"if the movie belongs to the genre\",\n",
    "            # location=\"top\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    movie_heat.set(\n",
    "        xlabel=\"Genres\", ylabel=\"Movies\", title=\"Summary of \"+ title_details\n",
    "    )\n",
    "    plt.show()\n",
    "    return movie_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqapp6NgKoKV"
   },
   "outputs": [],
   "source": [
    "all_movie_heat = plot_genre_heat(movies.iloc[:, 1:].set_index(\"TITLE\"),\n",
    "                                 \"genres for each movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvA5-t2GNEvk"
   },
   "outputs": [],
   "source": [
    "def get_types(movies):\n",
    "    \"\"\"Get how many types of different genre combinations\"\"\"\n",
    "    genre_comb = movies.iloc[:,2:].drop_duplicates()\n",
    "    cols_name = list(genre_comb.columns)\n",
    "    return genre_comb.sort_values(by=cols_name)[cols_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jr88Qa7iNIdZ"
   },
   "outputs": [],
   "source": [
    "movie_type_heat = plot_genre_heat(get_types(movies),\n",
    "                                 \"genres combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALDCTNbBz6-X"
   },
   "source": [
    "## All ratings in the MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "b911CXe7z6-X",
    "outputId": "e2f29b7e-de49-46fb-a2a0-8ae27cfb3cb5"
   },
   "outputs": [],
   "source": [
    "data_all = iqplot.histogram(\n",
    "    data=data, q=\"RATING\", bins=\"exact\", title=\"Rating for all movies\"\n",
    ")\n",
    "bokeh.io.show(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQUnrVYoz6-Y"
   },
   "outputs": [],
   "source": [
    "def plot_heat_rate(\n",
    "    df, title_details, x_tick_scale=None, y_tick_scale=None, ifreorder=False\n",
    "):\n",
    "    \"\"\"Plot heatmap where x-axis is the users, y-axis is the movie id,\n",
    "    and the color corresponds to the rating\"\"\"\n",
    "\n",
    "    try:\n",
    "        if \"TITLE\" in df.columns:\n",
    "            nrow = len(df.TITLE.unique())\n",
    "            df_heat = df.pivot(\"TITLE\", \"USER\", \"RATING\")\n",
    "        elif \"MOVIE_ID\" in df.columns:\n",
    "            nrow = len(df.MOVIE_ID.unique())\n",
    "            df_heat = df.pivot(\"MOVIE_ID\", \"USER\", \"RATING\")\n",
    "        elif \"MOVIE\" in df.columns:\n",
    "            nrow = len(df.MOVIE.unique())\n",
    "            df_heat = df.pivot(\"MOVIE\", \"USER\", \"RATING\")\n",
    "        else:\n",
    "            nrow = -1\n",
    "    except:\n",
    "        print(\"Resolving duplicating issue\")\n",
    "        df_heat = (\n",
    "            df[[\"TITLE\", \"USER\", \"RATING\"]]\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop=True)\n",
    "            .pivot_table(values=\"RATING\", index=[\"TITLE\", \"USER\"], aggfunc=\"mean\")\n",
    "            .unstack(1)\n",
    "        )\n",
    "        df_heat.columns = [user_id for r, user_id in df_heat.columns]\n",
    "\n",
    "    if nrow == None:\n",
    "        nscale = -20\n",
    "    elif nrow < 4:\n",
    "        nscale = 4\n",
    "    elif nrow > 1000:\n",
    "        nscale = 0.01\n",
    "        y_tick_scale = 50\n",
    "    else:\n",
    "        nscale = 0.6\n",
    "    p_height = nrow * nscale\n",
    "\n",
    "    if len(df.USER.unique()) > 50:\n",
    "        x_tick_scale = 50\n",
    "    \n",
    "    if ifreorder:\n",
    "        df_heat = df_heat.reindex(df.TITLE.unique())\n",
    "\n",
    "    plt.figure(figsize=(20, p_height))\n",
    "    rating_heat = sns.heatmap(\n",
    "        df_heat,\n",
    "        cmap=\"crest\",\n",
    "        cbar_kws=dict(\n",
    "            use_gridspec=False,\n",
    "            shrink=0.2,\n",
    "            ticks=list(range(1, 6)),\n",
    "            label=\"rating\",\n",
    "            location=\"top\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if x_tick_scale != None:\n",
    "        rating_heat.xaxis.set_major_locator(ticker.MultipleLocator(x_tick_scale))\n",
    "        rating_heat.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "\n",
    "    if y_tick_scale != None:\n",
    "        rating_heat.yaxis.set_major_locator(ticker.MultipleLocator(y_tick_scale))\n",
    "        rating_heat.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "    \n",
    "    rating_heat.set(xlabel=\"USER\", title=f\"Summary of {title_details}\")\n",
    "    plt.show()\n",
    "\n",
    "    return rating_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mpqg4_ODz6-Y"
   },
   "outputs": [],
   "source": [
    "def plot_rating_cat(df, cat):\n",
    "    \"\"\"Plot the rating grouped by user or movie\"\"\"\n",
    "    p = iqplot.stripbox(\n",
    "        data=df.sort_values(cat),\n",
    "        q=\"RATING\",\n",
    "        cats=cat,\n",
    "        plot_width=len(df[cat].unique())*10,\n",
    "        palette=list(\n",
    "            sns.color_palette(\"crest_r\", len(df[cat].unique())).as_hex()\n",
    "        ),\n",
    "        jitter=True,\n",
    "        marker_kwargs=dict(alpha=0.05),\n",
    "        q_axis=\"y\",\n",
    "        title=\"Rating per \" + cat,\n",
    "    )\n",
    "    p.xaxis.major_label_orientation = pi/2\n",
    "    bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2sUL5rQ6fVo"
   },
   "outputs": [],
   "source": [
    "def plot_ecdfs(df, q, ifshow=True):\n",
    "    \"\"\"Plot the ecdf based on popularity and average rating\"\"\"\n",
    "    counts_ecdf = iqplot.ecdf(\n",
    "            data=get_pop_movie(data, movies),\n",
    "            q=\"RATING_COUNTS\",\n",
    "            title=\"ECDF for all movie popularity\",\n",
    "        )\n",
    "    \n",
    "    rate_ecdf = iqplot.ecdf(\n",
    "            data=get_top_rate(data, movies), q=\"RATING\", title=\"ECDF for all rating\"\n",
    "        )\n",
    "\n",
    "    if ifshow:\n",
    "        bokeh.io.show(counts_ecdf)\n",
    "        bokeh.io.show(rate_ecdf)\n",
    "\n",
    "    return counts_ecdf, rate_ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "FUjxunpxz6-Y",
    "outputId": "cacb5a26-fa5f-40f0-b50f-88d88748c3bb"
   },
   "outputs": [],
   "source": [
    "rating_heat_all = plot_heat_rate(data,\n",
    "                                 \"full user movie rating\",\n",
    "                                 x_tick_scale=50, y_tick_scale=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "oMNtcOyaz6-Z",
    "outputId": "4969a661-b4e7-415f-9f2d-611c6d64cd67"
   },
   "outputs": [],
   "source": [
    "plot_rating_cat(data, \"USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "exorjr2wz6-Z",
    "outputId": "38bcd148-7352-4224-d79b-2e7c37641051"
   },
   "outputs": [],
   "source": [
    "plot_rating_cat(data, \"MOVIE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6yPiaPA6jLv"
   },
   "outputs": [],
   "source": [
    "counts_ecdf, rate_ecdf = plot_ecdfs(data, movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K66p1Snzz6-Z"
   },
   "source": [
    "## All ratings of the ten most popular (rated) movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhVAN34cz6-Z"
   },
   "outputs": [],
   "source": [
    "def get_pop_movie(data, movies):\n",
    "    \"\"\"Get the number and title of rated movies\"\"\"\n",
    "    movie_count = pd.DataFrame(data.MOVIE.value_counts()).reset_index()\n",
    "    movie_count.columns = [\"MOVIE_ID\", \"RATING_COUNTS\"]\n",
    "    return movie_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3tyggCOz6-Z"
   },
   "outputs": [],
   "source": [
    "def merge_title(df, movies, ifgenres=False):\n",
    "    \"\"\"Add movie titles\"\"\"\n",
    "    if \"MOVIE\" in df.columns:\n",
    "        df = df.rename(columns={\"MOVIE\": \"MOVIE_ID\"})\n",
    "    if not ifgenres:\n",
    "        movie_comb = movies.iloc[:, :2]\n",
    "    else:\n",
    "        movie_comb = movies\n",
    "\n",
    "    df = df.merge(movie_comb, left_on=\"MOVIE_ID\", right_on=\"MOVIE_ID\", how=\"left\")\n",
    "\n",
    "    df.loc[df.TITLE.isnull(), \"TITLE\"] = (\n",
    "        \"MOVIE_ID: \" + df.loc[df.TITLE.isnull(), \"MOVIE_ID\"]\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ILrbpxOz6-a"
   },
   "outputs": [],
   "source": [
    "def get_top_pop_movie_data(data, movies, topn):\n",
    "    \"\"\"Get the top rated movie ratings\"\"\"\n",
    "    data_lists = []\n",
    "    movie_count = get_pop_movie(data, movies)\n",
    "    for i in movie_count.MOVIE_ID[:topn]:\n",
    "        data_lists.append(data[data.MOVIE==i])\n",
    "    return merge_title(pd.concat(data_lists), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfQKqJWIFSJj"
   },
   "outputs": [],
   "source": [
    "def get_topn_str(df, topn):\n",
    "    \"\"\"Convert topn to all if None or number\"\"\"\n",
    "    if topn == None:\n",
    "        topn = len(df)\n",
    "        return \"all\"\n",
    "    else:\n",
    "        return str(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TwiPY97FSJj"
   },
   "outputs": [],
   "source": [
    "def hv_render(plot):\n",
    "    \"\"\"Render holoviews plots\"\"\"\n",
    "    # Take out the Bokeh object\n",
    "    p = hv.render(plot)\n",
    "    # Display using Bokeh\n",
    "    bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqX6HLdVFSJk"
   },
   "outputs": [],
   "source": [
    "def plot_vio(df, title_details, topn):\n",
    "    \"\"\"Plot violin plots\"\"\"\n",
    "    topn_str = get_topn_str(df, topn)\n",
    "    ncols = len(df.TITLE.unique())\n",
    "    if ncols < 700:\n",
    "        col_w = 50\n",
    "    else:\n",
    "        col_w = 20\n",
    "    \n",
    "    hv_violin = hv.Violin(\n",
    "        (df[\"TITLE\"], df[\"RATING\"]), [\"TITLE\"], \"Value\",\n",
    "    ).opts(\n",
    "        violin_color=hv.dim(\"TITLE\").str(),\n",
    "        cmap=\"GnBu_r\",\n",
    "        ylabel=\"RATING\",\n",
    "        title=f\"Rating violin plot for the {topn_str} {title_details} movies\",\n",
    "        ylim=(-1, 7),\n",
    "        show_legend=False,\n",
    "        colorbar=True,\n",
    "        # cut=1,\n",
    "        # bandwidth=1,\n",
    "        # inner='stick',\n",
    "        box_alpha=0.5,\n",
    "        xrotation=90,\n",
    "        width=col_w * len(df[\"TITLE\"].unique()),\n",
    "        height=300 + df.TITLE.map(len).max()*5,\n",
    "    )\n",
    "\n",
    "    hv_render(hv_violin)\n",
    "    \n",
    "    return hv_violin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2UC0clFz6-a"
   },
   "outputs": [],
   "source": [
    "def plot_topn_pop_rating(df, title_details, topn):\n",
    "    \"\"\"Plot the top n most popular/rated movies\"\"\"\n",
    "\n",
    "    topn_str = get_topn_str(df, topn)\n",
    "    \n",
    "    ncols = len(df.TITLE.unique())\n",
    "    if ncols < 100:\n",
    "        col_w = 50\n",
    "    else:\n",
    "        col_w = 20\n",
    "    p_w = ncols * col_w\n",
    "\n",
    "    if p_w < 500:\n",
    "        p_w = 500\n",
    "\n",
    "    topn_pop = iqplot.stripbox(\n",
    "        data=df,\n",
    "        q=\"RATING\",\n",
    "        cats=\"TITLE\",\n",
    "        palette=list(sns.color_palette(\"crest_r\", topn).as_hex()),\n",
    "        jitter=True,\n",
    "        top_level=\"box\",\n",
    "        q_axis=\"y\",\n",
    "        plot_width=p_w,\n",
    "        marker_kwargs=dict(alpha=0.05),\n",
    "        title=f\"Rating stripbox plot for the {topn_str} {title_details} movies\",\n",
    "    )\n",
    "\n",
    "    mapper = LinearColorMapper(\n",
    "        palette=list(sns.color_palette(\"crest\", topn).as_hex()), low=1, high=topn,\n",
    "    )\n",
    "    color_bar = ColorBar(\n",
    "        color_mapper=mapper,\n",
    "        padding=0,\n",
    "        location=(0, 0),\n",
    "        title=\"Most rated\",\n",
    "        title_standoff=10,\n",
    "    )\n",
    "\n",
    "    topn_pop.add_layout(color_bar, \"right\")\n",
    "    topn_pop.xaxis.major_label_orientation = pi / 2\n",
    "    topn_pop.xaxis.axis_label = \"MOVIE\"\n",
    "    bokeh.io.show(topn_pop)\n",
    "    return topn_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfI5r6PbFSJm"
   },
   "outputs": [],
   "source": [
    "def plot_hist_all(df, title_details, topn, ifoverlay=True):\n",
    "    \"\"\"Plot summary histogram\"\"\"\n",
    "    if ifoverlay:\n",
    "        set_cat = \"TITLE\"\n",
    "        set_kind = \"step\"\n",
    "        set_palette = list(\n",
    "            sns.color_palette(\"crest_r\", len(df.TITLE.unique())).as_hex()\n",
    "        )\n",
    "    else:\n",
    "        set_cat = None\n",
    "        set_kind = \"step_filled\"\n",
    "        set_palette = [sns.color_palette(\"crest\", 5).as_hex()[-1]] * len(df)\n",
    "\n",
    "    topn_str = get_topn_str(df, topn)\n",
    "    h = iqplot.histogram(\n",
    "        data=df,\n",
    "        bins=\"exact\",\n",
    "        q=\"RATING\",\n",
    "        cats=set_cat,\n",
    "        kind=set_kind,\n",
    "        palette=set_palette,\n",
    "        title=f\"Rating histogram for the {topn_str} {title_details} movies\",\n",
    "    )\n",
    "\n",
    "    # comment out for colab\n",
    "    # h.add_layout(h.legend[0], \"right\") \n",
    "\n",
    "    bokeh.io.show(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLVe7f9Pz6-a"
   },
   "outputs": [],
   "source": [
    "def plot_hist_list(df):\n",
    "    \"\"\"Plot a list of hist depaned on title\"\"\"\n",
    "\n",
    "    titles = df.TITLE.unique()\n",
    "    hists = [None] * len(titles)\n",
    "    for c, t in enumerate(titles):\n",
    "        hists[c] = iqplot.histogram(\n",
    "            data=df[df.TITLE == t],\n",
    "            bins=\"exact\",\n",
    "            q=\"RATING\",\n",
    "            title=t,\n",
    "            plot_width=200,\n",
    "            plot_height=150,\n",
    "        )\n",
    "\n",
    "    grid = gridplot(hists, ncols=10)\n",
    "\n",
    "    bokeh.io.show(column(grid))\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fnn26Q9wFSJm"
   },
   "outputs": [],
   "source": [
    "def plot_plots(\n",
    "    df,\n",
    "    topn,\n",
    "    title_details,\n",
    "    x_tick_scale=None,\n",
    "    y_tick_scale=None,\n",
    "    ifvio=True,\n",
    "    ifstripbox=True,\n",
    "    ifheat=True,\n",
    "    iftotallhist=True,\n",
    "    ifoverlayhist=True,\n",
    "    ifindhist=True,\n",
    "    ifreorder=True,\n",
    "):\n",
    "    \"\"\"Generate the stripbox or box, heatmap, and histograms\"\"\"\n",
    "\n",
    "    topn_str = get_topn_str(df, topn)\n",
    "    \n",
    "    if ifvio:\n",
    "        v = plot_vio(df, title_details, topn)\n",
    "            \n",
    "    if ifstripbox:\n",
    "        try:\n",
    "            poporrate = plot_topn_pop_rating(df, title_details, topn)\n",
    "        except:\n",
    "            poporrate = plot_top_rate(df, title_details, topn)\n",
    "    \n",
    "    if ifheat:\n",
    "        heat = plot_heat_rate(\n",
    "            df,\n",
    "            f\"{title_details} {topn_str} movies\",\n",
    "            x_tick_scale=x_tick_scale,\n",
    "            y_tick_scale=y_tick_scale,\n",
    "            ifreorder=ifreorder,\n",
    "        )\n",
    "    \n",
    "    if iftotallhist:\n",
    "        h_all = plot_hist_all(df,  title_details, topn, ifoverlay=False)\n",
    "        \n",
    "    if ifoverlayhist:\n",
    "        h_overlay = plot_hist_all(df,  title_details, topn, ifoverlay=True)\n",
    "\n",
    "    if ifindhist:\n",
    "        hists = plot_hist_list(df)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ULlcYaM_z6-b",
    "outputId": "8990ddef-5018-4bc3-9a6c-13a9e3b0f5af"
   },
   "outputs": [],
   "source": [
    "topn = 10\n",
    "topn_pop_df = get_top_pop_movie_data(data, movies, topn)\n",
    "plot_plots(topn_pop_df, topn, \"top rated\", x_tick_scale=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnopny1_z6-b"
   },
   "source": [
    "## All ratings of the ten best movies with the highest average ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cu-kRuh7YvR"
   },
   "outputs": [],
   "source": [
    "def get_top_rate(data, movies):\n",
    "    \"\"\"Sort by top avg rating\"\"\"\n",
    "    return (\n",
    "        data.set_index([\"MOVIE\"])\n",
    "        .groupby([\"MOVIE\"])\n",
    "        .mean()\n",
    "        .sort_values([\"RATING\"], ascending=False)\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRNPPDHtz6-b"
   },
   "outputs": [],
   "source": [
    "def get_top_rate_full(data, movies, topn):\n",
    "    \"\"\"Get the top rated movies\"\"\"\n",
    "    top_rate = get_top_rate(data, movies)\n",
    "\n",
    "    df_list = []\n",
    "    \n",
    "    for i in top_rate.MOVIE[:topn]:\n",
    "        df_list.append(data[data.MOVIE==i])\n",
    "    \n",
    "    return merge_title(pd.concat(df_list), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6RT2EOVz6-b"
   },
   "outputs": [],
   "source": [
    "def plot_top_rate(df, title_details, topn):\n",
    "    \"\"\"Plot strip plots of the top rated movies\"\"\"\n",
    "    \n",
    "    if topn == None:\n",
    "        topn = len(df)\n",
    "        topn_str = \"all\"\n",
    "    else:\n",
    "        topn_str = topn\n",
    "        \n",
    "    ncols = len(df.TITLE.unique())\n",
    "    if ncols < 20:\n",
    "        col_w = 50\n",
    "    else:\n",
    "        col_w = 10\n",
    "    p_w = ncols*col_w\n",
    "    \n",
    "    if p_w < 200:\n",
    "        p_w = 200\n",
    "        \n",
    "    topn_rate = iqplot.strip(\n",
    "        data=df,\n",
    "        q=\"RATING\",\n",
    "        cats=\"TITLE\",\n",
    "        palette=list(sns.color_palette(\"crest_r\", \n",
    "                                       len(df.RATING.unique())).as_hex()),\n",
    "        jitter=True,\n",
    "        q_axis=\"y\",\n",
    "        plot_width=p_w,\n",
    "        marker_kwargs=dict(alpha=0.5),\n",
    "        color_column=\"RATING\",\n",
    "        title=f\"Rating for the {title_details} {topn_str} movies\",\n",
    "    )\n",
    "\n",
    "    topn_rate.xaxis.major_label_orientation = pi / 2\n",
    "    topn_rate.xaxis.axis_label = \"MOVIE\"\n",
    "    bokeh.io.show(topn_rate)\n",
    "    return topn_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EEHxPWRYz6-c",
    "outputId": "9640c3f4-e42f-4d5e-ef0c-7893262ffa9a"
   },
   "outputs": [],
   "source": [
    "topn = 10\n",
    "topn_rate_df = get_top_rate_full(data, movies, topn)\n",
    "plot_plots(topn_rate_df, topn, \"top average rating\" ,ifvio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVd1idn0z6-c"
   },
   "source": [
    "## All ratings of movies from different genres of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VXGQD_M4z6-c",
    "outputId": "5e950146-5420-4ed5-816d-5664f8ffa99e"
   },
   "outputs": [],
   "source": [
    "topn = None\n",
    "genre_df = merge_title(data, movies, ifgenres=True)\n",
    "genres = movies.columns[2:]\n",
    "for g in genres:\n",
    "    g_df = genre_df[genre_df[g] == 1]\n",
    "    plot_plots(g_df, topn, g, ifstripbox=False, ifoverlayhist=False, \n",
    "               ifindhist=False, ifreorder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k4lSvd87y8L"
   },
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6YC9omx8g8p"
   },
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xk_mjLiWOw94"
   },
   "source": [
    "### Matrix factorization and data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6DnP5EL8n1Q"
   },
   "outputs": [],
   "source": [
    "def grad_U(Ui, Yij, Vj, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*Ui + eta * Vj * (Yij - np.dot(Ui,Vj))     \n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    return (1-reg*eta)*Vj + eta * Ui * (Yij - np.dot(Ui,Vj))\n",
    "\n",
    "def get_err(U, V, Y, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    # Compute mean squared error on each data point in Y; include\n",
    "    # regularization penalty in error calculations.\n",
    "    # We first compute the total squared squared error\n",
    "    err = 0.0\n",
    "    for (i,j,Yij) in Y:\n",
    "        err += 0.5 *(Yij - np.dot(U[i-1], V[:,j-1]))**2\n",
    "    # Add error penalty due to regularization if regularization\n",
    "    # parameter is nonzero\n",
    "    if reg != 0:\n",
    "        U_frobenius_norm = np.linalg.norm(U, ord='fro')\n",
    "        V_frobenius_norm = np.linalg.norm(V, ord='fro')\n",
    "        err += 0.5 * reg * (U_frobenius_norm ** 2)\n",
    "        err += 0.5 * reg * (V_frobenius_norm ** 2)\n",
    "    # Return the mean of the regularized error\n",
    "    return err / float(len(Y))\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Initialize U, V  \n",
    "    U = np.random.random((M,K)) - 0.5\n",
    "    V = np.random.random((K,N)) - 0.5\n",
    "    size = Y.shape[0]\n",
    "    delta = None\n",
    "    indices = np.arange(size)    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Run an epoch of SGD\n",
    "        before_E_in = get_err(U, V, Y, reg)\n",
    "        np.random.shuffle(indices)\n",
    "        for ind in indices:\n",
    "            (i,j, Yij) = Y[ind]\n",
    "            # Update U[i], V[j]\n",
    "            U[i-1] = grad_U(U[i-1], Yij, V[:,j-1], reg, eta)\n",
    "            V[:,j-1] = grad_V(V[:,j-1], Yij, U[i-1], reg, eta);\n",
    "        # At end of epoch, print E_in\n",
    "        E_in = get_err(U, V, Y, reg)\n",
    "        print(\"Epoch %s, E_in (regularized MSE): %s\"%(epoch + 1, E_in))\n",
    "\n",
    "        # Compute change in E_in for first epoch\n",
    "        if epoch == 0:\n",
    "            delta = before_E_in - E_in\n",
    "\n",
    "        # If E_in doesn't decrease by some fraction <eps>\n",
    "        # of the initial decrease in E_in, stop early            \n",
    "        elif before_E_in - E_in < eps * delta:\n",
    "            break\n",
    "    return (U, V, get_err(U, V, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfSfBYYRMB9L"
   },
   "outputs": [],
   "source": [
    "def get_MNY(Y_train_df, Y_test_df):\n",
    "    \"\"\"Return Y_train, Y_test, M, N, \n",
    "    where M is unique user IDs and N is unique movie IDs\"\"\"\n",
    "    return (\n",
    "        Y_train_df.to_numpy(),\n",
    "        Y_test_df.to_numpy(),\n",
    "        int(max(max(Y_train_df.USER), max(Y_test_df.USER))),\n",
    "        int(max(max(Y_train_df.MOVIE), max(Y_test_df.MOVIE))),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRiGQBr69t50"
   },
   "outputs": [],
   "source": [
    "def get_UV_proj(U, V):\n",
    "    \"\"\"Get the UV projection\"\"\"   \n",
    "    A, sigma, B = np.linalg.svd(V,  full_matrices=False)\n",
    "    A_two_cols = A[:, 0:2]\n",
    "\n",
    "    U_proj = A_two_cols.transpose()@U.transpose()\n",
    "    V_proj = A_two_cols.transpose()@V\n",
    "    \n",
    "    return U_proj, V_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WcHPyULPFna"
   },
   "outputs": [],
   "source": [
    "def get_top_pop_movie_data(data, movies, topn):\n",
    "    \"\"\"Get the top rated movie ratings\"\"\"\n",
    "    data_lists = []\n",
    "    movie_count = get_pop_movie(data, movies)\n",
    "    for i in movie_count.MOVIE_ID[:topn]:\n",
    "        data_lists.append(data[data.MOVIE == i])\n",
    "    return merge_title(pd.concat(data_lists), movies)\n",
    "\n",
    "\n",
    "def get_topn_pop_n_rate_proj(\n",
    "    df, rankcols, topn=10, cutoff=5, mostorleast=\"most\", genres=None\n",
    "):\n",
    "    \"\"\"Return top n rated and or pop movies, with and without cut off\"\"\"\n",
    "\n",
    "    df = df[df.RATING_COUNTS >= cutoff]\n",
    "\n",
    "    if genres != None:\n",
    "        df = df[df[genres] == 1]\n",
    "\n",
    "    # if ascending\n",
    "    if mostorleast == \"most\":\n",
    "        TorF = False\n",
    "    else:\n",
    "        TorF = True\n",
    "\n",
    "    if isinstance(rankcols, list) and len(rankcols) > 1:\n",
    "        ifasc = [TorF] * len(rankcols)\n",
    "    elif (isinstance(rankcols, list) and len(rankcols) == 1) or isinstance(\n",
    "        rankcols, str\n",
    "    ):\n",
    "        ifasc = TorF\n",
    "\n",
    "    return df.sort_values(by=rankcols, ascending=ifasc).iloc[:topn, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRXA2afq97m0"
   },
   "outputs": [],
   "source": [
    "def comb_rate_pop(data, movies, ifgenres=True):\n",
    "    \"\"\"Combine rating and popularity and add titles\"\"\"\n",
    "    return merge_title(\n",
    "        (\n",
    "            get_top_rate(data, movies)\n",
    "            .rename(columns={\"RATING\": \"AVG_RATING\"})\n",
    "            .merge(get_pop_movie(data, movies), left_on=\"MOVIE\", right_on=\"MOVIE_ID\")[\n",
    "                [\"MOVIE_ID\", \"AVG_RATING\", \"RATING_COUNTS\"]\n",
    "            ]\n",
    "            .sort_values(by=\"MOVIE_ID\")\n",
    "        ),\n",
    "        movies,\n",
    "        ifgenres=ifgenres,\n",
    "    )\n",
    "\n",
    "def comb_proj_rate_pop(proj, data, movies, ifgenres=True):\n",
    "    \"\"\"Combine the projections with all other info\"\"\"\n",
    "    proj_df = pd.DataFrame(proj.T, columns=[\"proj_1\", \"proj_2\"])\n",
    "    comb = proj_df.merge(\n",
    "        comb_rate_pop(data, movies, ifgenres=ifgenres),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    comb.RATING_COUNTS = comb.RATING_COUNTS.astype(np.float)\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y33Ir55CSe6t"
   },
   "outputs": [],
   "source": [
    "Y_train, Y_test, M, N = get_MNY(Y_train_df, Y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHxIFHE8O3Vr"
   },
   "source": [
    "### Surprise prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C484hwklO48P"
   },
   "outputs": [],
   "source": [
    "def use_surprise(\n",
    "    Y_train_df, n_factors, n_epochs, lr_all, reg_all, ifbiased, ifreg_bubi\n",
    "):\n",
    "    \"\"\"Use surprise to find pu, qi\"\"\"\n",
    "\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    train_dataset = Dataset.load_from_df(Y_train_df, reader)\n",
    "\n",
    "    train_dataset_object = train_dataset.build_full_trainset()\n",
    "\n",
    "    if ifreg_bubi:\n",
    "        reg_bu = reg_all\n",
    "        reg_bi = reg_all\n",
    "    else:\n",
    "        reg_bu = None\n",
    "        reg_bi = None\n",
    "    \n",
    "    if ifbiased:\n",
    "        reg_all = 0\n",
    "    \n",
    "    algo = SVD(\n",
    "        n_factors=n_factors,\n",
    "        n_epochs=n_epochs,\n",
    "        lr_all=lr_all,\n",
    "        reg_all=reg_all,\n",
    "        reg_bu=reg_bu,\n",
    "        reg_bi=reg_bi,\n",
    "        biased=ifbiased,\n",
    "        random_state=42,\n",
    "    )\n",
    "    cross_validate(algo, train_dataset, measures=[\"RMSE\"], cv=5, verbose=True)\n",
    "\n",
    "    algo.fit(train_dataset_object)\n",
    "\n",
    "    print(\"pu shape\", algo.pu.shape)\n",
    "    print(\"qi shape\", algo.qi.shape)\n",
    "\n",
    "    pred = []\n",
    "    for rows in Y_test_df.iterrows():\n",
    "        uid = str(rows[1][0])\n",
    "        iid = str(rows[1][1])\n",
    "        rui = rows[1][2]\n",
    "\n",
    "        # get a prediction for specific users and items.\n",
    "        pred.append(algo.predict(uid, iid, r_ui=rui))\n",
    "\n",
    "    return surprise.accuracy.rmse(pred), algo.pu[:,:2].T, algo.qi[:,:2].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJF0v1zyO1WK"
   },
   "source": [
    "### Plotting prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHMx6C5bMcMb"
   },
   "outputs": [],
   "source": [
    "def ecdf_vals(df, cat):\n",
    "    \"\"\"Compute x and y values for plotting an ECDF\"\"\"\n",
    "    data = df[cat]\n",
    "    return pd.DataFrame(\n",
    "        {\"x\": np.sort(data), \"ECDF\": np.arange(1, len(data) + 1) / len(data)}\n",
    "    )\n",
    "\n",
    "def plot_pop_hist(meta_rate_pop):\n",
    "    \"\"\"Histogram for total rating counts, aka popularity\"\"\"\n",
    "    count_hist = hv.render(\n",
    "        (\n",
    "            hv.Histogram(\n",
    "                np.histogram(\n",
    "                    meta_rate_pop[\"RATING_COUNTS\"], int(len(meta_rate_pop) / 10),\n",
    "                )\n",
    "            )\n",
    "            .opts(width=800, height=90,)\n",
    "            .relabel()\n",
    "            .opts(xaxis=\"top\", yticks=[0, 300], line_color=\"grey\", fill_color=\"grey\",)\n",
    "        )\n",
    "    )\n",
    "    count_hist.xaxis.major_label_text_font_size = \"0pt\"\n",
    "    count_hist.xaxis.axis_label = None\n",
    "    return count_hist\n",
    "\n",
    "def plot_pop_ecdf(meta_rate_pop, title_details):\n",
    "    \"\"\"ecdf for total rating counts, aka popularity\"\"\"\n",
    "    counts_ecdf = iqplot.ecdf(\n",
    "        data=meta_rate_pop,\n",
    "        q=\"RATING_COUNTS\",\n",
    "        plot_width=800,\n",
    "        plot_height=160,\n",
    "        x_axis_location=\"above\",\n",
    "        title=\"Movie-user projection \" + title_details,\n",
    "        palette=[\"#808080\"],\n",
    "        marker_kwargs=dict(alpha=0.5),\n",
    "    )\n",
    "    counts_ecdf.yaxis[0].ticker = [0, 0.5, 1]\n",
    "    counts_ecdf.xgrid.visible = False\n",
    "    counts_ecdf.ygrid.visible = False\n",
    "    counts_ecdf.x_range.range_padding = 0.038\n",
    "    counts_ecdf.title.text_font_size = \"24px\"\n",
    "    counts_ecdf.title.align = \"center\"\n",
    "    return counts_ecdf\n",
    "\n",
    "def plot_avg_hist(meta_rate_pop):\n",
    "    \"\"\"Histogram for average rating\"\"\"\n",
    "    avg_hist, avg_hist_edges = np.histogram(\n",
    "        meta_rate_pop[\"AVG_RATING\"], int(len(meta_rate_pop) / 10),\n",
    "    )\n",
    "    avg_hist_p = figure(plot_width=115, plot_height=800, y_axis_location=\"right\")\n",
    "    avg_hist_p.quad(\n",
    "        top=avg_hist_edges[1:],\n",
    "        bottom=avg_hist_edges[:-1],\n",
    "        left=0,\n",
    "        right=avg_hist,\n",
    "        line_alpha=0,\n",
    "        fill_color=list(sns.color_palette(\"GnBu_r\", len(avg_hist)).as_hex()),\n",
    "    )\n",
    "    avg_hist_p.yaxis.axis_label = None\n",
    "    avg_hist_p.xaxis.axis_label = \"Frequency\"\n",
    "    avg_hist_p.y_range.flipped = True\n",
    "    avg_hist_p.yaxis[0].ticker = list(np.linspace(1, 5, 9))\n",
    "    avg_hist_p.yaxis.minor_tick_line_color = None  # turn off y-axis minor ticks\n",
    "    avg_hist_p.yaxis.major_label_text_font_size = \"0pt\"\n",
    "    avg_hist_p.xaxis[0].ticker = [0, 50, 100]\n",
    "    avg_hist_p.xgrid.visible = False\n",
    "    avg_hist_p.ygrid.visible = False\n",
    "    avg_hist_p.y_range.range_padding = 0.025\n",
    "    return avg_hist_p\n",
    "\n",
    "def plot_rate_ecdf(data, movies):\n",
    "    \"\"\"Plot ecdf for all rating\"\"\"\n",
    "\n",
    "    rate_ecdf = figure(plot_width=150, plot_height=800, y_axis_location=\"right\")\n",
    "    rate_ecdf_val = ecdf_vals(get_top_rate(data, movies), \"RATING\")\n",
    "    rate_ecdf_source = ColumnDataSource(rate_ecdf_val)\n",
    "\n",
    "    exp_cmap = LinearColorMapper(\n",
    "        palette=list(sns.color_palette(\"GnBu\", len(rate_ecdf_val[\"ECDF\"])).as_hex()),\n",
    "        low=0,\n",
    "        high=1,\n",
    "    )\n",
    "    rate_ecdf.circle(\n",
    "        \"ECDF\",\n",
    "        \"x\",\n",
    "        source=rate_ecdf_source,\n",
    "        line_color=None,\n",
    "        fill_color={\"field\": \"ECDF\", \"transform\": exp_cmap},\n",
    "    )\n",
    "\n",
    "    rate_ecdf.yaxis.axis_label = \"AVE_RATING\"\n",
    "    rate_ecdf.xaxis.axis_label = \"ECDF\"\n",
    "    rate_ecdf.xaxis[0].ticker = [0, 0.5, 1]\n",
    "    rate_ecdf.yaxis[0].ticker = list(np.linspace(1, 5, 9))\n",
    "    rate_ecdf.xgrid.visible = False\n",
    "    rate_ecdf.ygrid.visible = False\n",
    "    rate_ecdf.y_range.range_padding = 0.025\n",
    "    \n",
    "    return rate_ecdf\n",
    "\n",
    "def get_hists_ecdfs(meta_rate_pop, title_details):\n",
    "    \"\"\"Plot the summary histogram and ecdf for \n",
    "    based on popularity and the average rating\"\"\"\n",
    "\n",
    "    # histogram for total rating counts, aka popularity\n",
    "    count_hist = plot_pop_hist(meta_rate_pop)\n",
    "\n",
    "    # ecdf for total rating counts, aka popularity\n",
    "    counts_ecdf = plot_pop_ecdf(meta_rate_pop, title_details)\n",
    "\n",
    "    # histogram for average rating\n",
    "    avg_hist_p = plot_avg_hist(meta_rate_pop)\n",
    "    \n",
    "    # plot ecdf for all rating\n",
    "    rate_ecdf = plot_rate_ecdf(data, movies)\n",
    "    \n",
    "    return count_hist, counts_ecdf, avg_hist_p, rate_ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq9TaKnhMfi3"
   },
   "outputs": [],
   "source": [
    "def plot_V_pts(comb_V_df):\n",
    "    \"\"\"plot V - movie as scatter plots\"\"\"\n",
    "    popts = opts.Points(\n",
    "        color=\"AVG_RATING\",\n",
    "        size=dim(\"RATING_COUNTS\") * 0.2,\n",
    "        alpha=0.5,\n",
    "        line_alpha=1,\n",
    "        line_width=2,\n",
    "        width=800,\n",
    "        height=800,\n",
    "        cmap=\"GnBu\",\n",
    "        colorbar=True,\n",
    "    )\n",
    "\n",
    "    return hv.Points(\n",
    "        comb_V_df,\n",
    "        kdims=[\"proj_1\", \"proj_2\"],\n",
    "        vdims=[\"AVG_RATING\", \"RATING_COUNTS\"],\n",
    "        label=\"movie projection\",\n",
    "    ).opts(popts)\n",
    "\n",
    "def plot_U_pts(comb_U_df):\n",
    "    \"\"\"plot U - users as scatter plots\"\"\"\n",
    "\n",
    "    return hv.Points(\n",
    "        comb_U_df,\n",
    "        kdims=[\"proj_1\", \"proj_2\"],\n",
    "        vdims=[\"AVG_RATING\", \"RATING_COUNTS\"],\n",
    "        label=\"user projection\",\n",
    "    ).opts(\n",
    "        fill_color=\"grey\",\n",
    "        fill_alpha=0.25,\n",
    "        line_color=\"grey\",\n",
    "        line_width=0.1,\n",
    "        show_legend=True,\n",
    "    )\n",
    "\n",
    "def plot_selected_V(\n",
    "    df, legend_label, color_list, pt_size=2, iflabel=True, xoff=0, yoff=-0.1\n",
    "):\n",
    "    \"\"\"Plot top n popular movie with Vs\"\"\"\n",
    "    labels = hv.Labels(\n",
    "        {(\"proj_1\", \"proj_2\"): df, \"text\": df.TITLE}, [\"proj_1\", \"proj_2\"], \"text\",\n",
    "    )\n",
    "\n",
    "    if iflabel:\n",
    "        return (\n",
    "            hv.Points(df, kdims=[\"proj_1\", \"proj_2\"], label=legend_label) * labels\n",
    "        ).opts(\n",
    "            opts.Points(color=color_list, fill_alpha=0.5, line_width=2, size=pt_size),\n",
    "            opts.Labels(text_font_size=\"10pt\", xoffset=xoff, yoffset=yoff),\n",
    "        )\n",
    "    else:\n",
    "        return (hv.Points(df, kdims=[\"proj_1\", \"proj_2\"], label=legend_label)).opts(\n",
    "            color=color_list, fill_alpha=0.5, line_width=2\n",
    "        )\n",
    "    \n",
    "def get_legend_highlow(rankcols, mostorleast=\"most\"):\n",
    "    \"\"\"Determine how to phrase legend\"\"\"\n",
    "\n",
    "    if mostorleast == \"most\":\n",
    "        morl = \"most\"\n",
    "        horl = \"hights\"\n",
    "    else:\n",
    "        morl = \"least\"\n",
    "        horl = \"lowest\"\n",
    "\n",
    "    if rankcols == [\"RATING_COUNTS\", \"AVG_RATING\"]:\n",
    "        leg = f\"{morl} & {horl} rated\"\n",
    "    elif rankcols == [\"AVG_RATING\", \"RATING_COUNTS\"]:\n",
    "        leg = f\"{horl} & {morl} rated\"\n",
    "    elif rankcols == [\"AVG_RATING\"] or rankcols == \"AVG_RATING\":\n",
    "        leg = f\"{horl} rated\"\n",
    "    elif rankcols == [\"RATING_COUNTS\"] or rankcols == \"RATING_COUNTS\":\n",
    "        leg = f\"{morl} rated\"\n",
    "\n",
    "    return leg\n",
    "\n",
    "\n",
    "def get_dfs(\n",
    "    comb_V_df, rankcols, three_genres, topn=10, cutoff=5, mostorleast=\"most\",\n",
    "):\n",
    "    \"\"\"Get the list of dfs for given genre, rating, popularities\"\"\"\n",
    "    g_dfs = [None] * 3\n",
    "    for g, genre in enumerate(three_genres):\n",
    "        g_dfs[g] = get_topn_pop_n_rate_proj(\n",
    "            comb_V_df,\n",
    "            rankcols,\n",
    "            topn=topn,\n",
    "            cutoff=cutoff,\n",
    "            mostorleast=mostorleast,\n",
    "            genres=genre,\n",
    "        )\n",
    "    return g_dfs\n",
    "\n",
    "\n",
    "def get_g_handpick_dfs(df, chosen_id_dict):\n",
    "    \"\"\"Return sliced dataframe with chosen IDs\"\"\"\n",
    "    dfs = [None] * len(chosen_id_dict)\n",
    "\n",
    "    for i, (k, v) in enumerate(chosen_id_dict.items()):\n",
    "        dfs[i] = df[df.MOVIE_ID.isin(v)]\n",
    "\n",
    "    return list(chosen_id_dict.keys()), dfs\n",
    "\n",
    "\n",
    "def plot_overlay_pt(\n",
    "    comb_V_df,\n",
    "    comb_U_df,\n",
    "    three_genres,\n",
    "    rankcols,\n",
    "    ifhandpick=False,\n",
    "    chosen_id_dict=None,\n",
    "    topn=10,\n",
    "    cutoff=5,\n",
    "    mostorleast=\"most\",\n",
    "    iflabel=False,\n",
    "    xoff=0,\n",
    "    yoff=-0.1,\n",
    "):\n",
    "\n",
    "    \"\"\"generate point plots overlays with 3 chosen genres\"\"\"\n",
    "\n",
    "    add_colors = sns.color_palette(\"YlOrBr\", 10).as_hex()\n",
    "\n",
    "    topn_pop_V_proj = get_topn_pop_n_rate_proj(comb_V_df, \"RATING_COUNTS\")\n",
    "    # df, rankcols, topn=10, cutoff=5, mostorleast=\"most\", genres=None\n",
    "    topn_rate_V_proj_5_cut = get_topn_pop_n_rate_proj(comb_V_df, \"AVG_RATING\")\n",
    "\n",
    "    \"\"\"g_dfs = [None] * 3\n",
    "    for g, genre in enumerate(three_genres):\n",
    "        g_dfs[g] = get_topn_pop_n_rate_proj(\n",
    "            comb_V_df,\n",
    "            rankcols,\n",
    "            topn=topn,\n",
    "            cutoff=cutoff,\n",
    "            mostorleast=mostorleast,\n",
    "            genres=genre,\n",
    "        )\"\"\"\n",
    "\n",
    "    if ifhandpick and chosen_id_dict != None:\n",
    "        three_genres, g_dfs = get_g_handpick_dfs(comb_V_df, chosen_id_dict)\n",
    "        leg = \"Chosen\"\n",
    "        # iflabel = True\n",
    "    else: \n",
    "        g_dfs = get_dfs(\n",
    "            comb_V_df,\n",
    "            rankcols,\n",
    "            three_genres,\n",
    "            topn=topn,\n",
    "            cutoff=cutoff,\n",
    "            mostorleast=mostorleast)\n",
    "        leg = get_legend_highlow(rankcols, mostorleast=mostorleast)\n",
    "    \n",
    "    overlay_pt = hv.render(\n",
    "        plot_V_pts(comb_V_df)\n",
    "        * plot_U_pts(comb_U_df)\n",
    "        * plot_selected_V(\n",
    "            topn_pop_V_proj, \n",
    "            \"most rated\", \n",
    "            list(add_colors)[1], \n",
    "            pt_size=10, \n",
    "            iflabel=True, \n",
    "            xoff=xoff,\n",
    "            yoff=yoff,\n",
    "        )\n",
    "        * plot_selected_V(\n",
    "            topn_rate_V_proj_5_cut,\n",
    "            \"highest rating (≥5 ratings)\",\n",
    "            list(add_colors)[3],\n",
    "            pt_size=8,\n",
    "            iflabel=True,\n",
    "            xoff=xoff,\n",
    "            yoff=yoff,\n",
    "        )\n",
    "        * plot_selected_V(\n",
    "            g_dfs[0],\n",
    "            f\"{leg} {three_genres[0]}\",\n",
    "            list(add_colors)[5],\n",
    "            pt_size=6,\n",
    "            iflabel=iflabel,\n",
    "            xoff=xoff,\n",
    "            yoff=yoff,\n",
    "        )\n",
    "        * plot_selected_V(\n",
    "            g_dfs[1],\n",
    "            f\"{leg} {three_genres[1]}\",\n",
    "            list(add_colors)[7],\n",
    "            pt_size=4,\n",
    "            iflabel=iflabel,\n",
    "            xoff=xoff,\n",
    "            yoff=yoff,\n",
    "        )\n",
    "        * plot_selected_V(\n",
    "            g_dfs[2],\n",
    "            f\"{leg} {three_genres[2]}\",\n",
    "            list(add_colors)[9],\n",
    "            pt_size=2,\n",
    "            iflabel=iflabel,\n",
    "            xoff=xoff,\n",
    "            yoff=yoff,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return overlay_pt\n",
    "\n",
    "\n",
    "def plot_layout(counts_ecdf, count_hist, overlay_pt, avg_hist_p, rate_ecdf):\n",
    "    \"\"\"Plot the layout with points, ecdfs, and histograms\"\"\"\n",
    "    layout = gridplot(\n",
    "        [\n",
    "            [counts_ecdf, None, None],\n",
    "            [count_hist, None, None],\n",
    "            [overlay_pt, avg_hist_p, rate_ecdf],\n",
    "        ],\n",
    "        merge_tools=True,\n",
    "    )\n",
    "    bokeh.io.show(layout)\n",
    "    \n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuJfVIGgMiDf"
   },
   "outputs": [],
   "source": [
    "def get_UV2layout(\n",
    "    U,\n",
    "    V,\n",
    "    data,\n",
    "    movies,\n",
    "    three_genres,\n",
    "    rankcols,\n",
    "    title_details,\n",
    "    ifhandpick=False,\n",
    "    chosen_id_dict=None,\n",
    "    topn=10,\n",
    "    cutoff=5,\n",
    "    mostorleast=\"most\",\n",
    "    iflabel=False,\n",
    "    xoff=0,\n",
    "    yoff=-0.1,\n",
    "    needproj=True,\n",
    "):\n",
    "    \"\"\"Put together the whole process\"\"\"\n",
    "    if needproj:\n",
    "        U_proj, V_proj = get_UV_proj(U, V)\n",
    "    else:\n",
    "        U_proj, V_proj = (U, V)\n",
    "\n",
    "    comb_V_df = comb_proj_rate_pop(V_proj, data, movies)\n",
    "    comb_U_df = comb_proj_rate_pop(U_proj, data, movies)\n",
    "\n",
    "    counts_ecdf, rate_ecdf = plot_ecdfs(data, movies, ifshow=False)\n",
    "\n",
    "    meta_rate_pop = comb_rate_pop(data, movies)\n",
    "    count_hist, counts_ecdf, avg_hist_p, rate_ecdf = get_hists_ecdfs(\n",
    "        meta_rate_pop, title_details\n",
    "    )\n",
    "\n",
    "    overlay_pt = plot_overlay_pt(\n",
    "        comb_V_df,\n",
    "        comb_U_df,\n",
    "        three_genres,\n",
    "        rankcols,\n",
    "        ifhandpick=ifhandpick,\n",
    "        chosen_id_dict=chosen_id_dict,\n",
    "        topn=topn,\n",
    "        cutoff=cutoff,\n",
    "        mostorleast=mostorleast,\n",
    "        iflabel=iflabel,\n",
    "        xoff=xoff,\n",
    "        yoff=yoff,\n",
    "    )\n",
    "    \n",
    "    layout = plot_layout(counts_ecdf, count_hist, overlay_pt, avg_hist_p, rate_ecdf)\n",
    "    return (\n",
    "        U_proj,\n",
    "        V_proj,\n",
    "        comb_V_df,\n",
    "        comb_U_df,\n",
    "        counts_ecdf,\n",
    "        count_hist,\n",
    "        overlay_pt,\n",
    "        avg_hist_p,\n",
    "        rate_ecdf,\n",
    "        layout,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE6jQLleMIYT"
   },
   "outputs": [],
   "source": [
    "def get_list_movies(data, head_no):\n",
    "    \"\"\" selects the first head_no items from data and returns 3 lists of ids, genre and titles\"\"\"   \n",
    "\n",
    "    list_movies_id = [d[1] for d in data.head(head_no).values]\n",
    "\n",
    "    list_movies_genre = []\n",
    "    list_movies_titles = []\n",
    "    for idx in list_movies_id:\n",
    "        movie_id_df = movies[movies[\"MOVIE_ID\"] == idx]\n",
    "        list_cols = []\n",
    "        for i, v in enumerate(movie_id_df.values[0,:]):\n",
    "            if v == 1:\n",
    "                list_cols.append(movie_id_df.columns[i])\n",
    "        list_movies_genre.append(list_cols)\n",
    "        list_movies_titles.append(movie_id_df.values[0,1])\n",
    "        \n",
    "    return list_movies_id, list_movies_genre, list_movies_titles\n",
    "\n",
    "# Some visualizations\n",
    "def visualize(V_proj, movie_titles, movie_genre):\n",
    "    \"\"\" Plots V_proj with annotations from the lists of ids, genre and titles\"\"\"   \n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.axhline(y=0, color=\"r\")\n",
    "    ax.axvline(x=0, color=\"r\")\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    m_proj0 = np.mean(V_proj[0,:])\n",
    "    m_proj1 = np.mean(V_proj[1,:])\n",
    "    ax.plot(V_proj[0,:] - m_proj0, V_proj[1,:] - m_proj1,\"*\")\n",
    "    ax.set_xlabel(\"V proj 0\")\n",
    "    ax.set_ylabel(\"V proj 1\")\n",
    "    offset = 0.01\n",
    "    for i, txt in enumerate(list_movies_titles):\n",
    "        ax.annotate(txt, (V_proj[0][i] - m_proj0 + offset, V_proj[1][i] - m_proj1 + offset), fontsize=8)\n",
    "\n",
    "    for i, txt in enumerate(list_movies_genre):\n",
    "        ax.annotate(txt, (V_proj[0][i] - m_proj0, V_proj[1][i] - m_proj1 - 5*offset), fontsize=8)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-jKWHGJMZZx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKZBARyx8nMj"
   },
   "outputs": [],
   "source": [
    "Y_train, Y_test, M, N = get_MNY(Y_train_df, Y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEDbmH7rtSzY"
   },
   "source": [
    "### Choose movies and matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiZSJL2jtUJL"
   },
   "outputs": [],
   "source": [
    "chosen_id_dict = {\n",
    "    \"COMEDY\": [1, 70, 94, 168, 202, 257, 894, 902, 820, 173],\n",
    "    \"ROMANCE\": [50, 69, 70, 133, 155, 161, 172, 213, 313, 465],\n",
    "    \"SCI-FI\": [89, 96, 109, 176, 195, 228, 229, 343, 429, 449],\n",
    "}\n",
    "three_genres = [\"COMEDY\", \"ROMANCE\", \"SCI-FI\"]\n",
    "rankcols = [\"AVG_RATING\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z51i-CIa71sU"
   },
   "source": [
    "## Method One (No bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxrP4_85NeAq"
   },
   "source": [
    "### HW (No bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1yIKn_3hr9s"
   },
   "outputs": [],
   "source": [
    "def run_non_bias_model(Y_train, M, N, Ks, eta):\n",
    "    \"\"\"The non-biased HW\"\"\"\n",
    "    # print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "    reg = 0\n",
    "\n",
    "    # Use to compute Ein and Eout\n",
    "    U1, V1, err_training = train_model(M, N, Ks, eta, reg, Y_train)\n",
    "    err_test = get_err(U1, V1, Y_test)\n",
    "\n",
    "    print(\"Err training\", err_training)\n",
    "    print(\"Err testing\", err_test)\n",
    "    # print(\"dim U [m x k]\", U1.shape)\n",
    "    # print(\"dim V [k x n]\", V1.shape)\n",
    "\n",
    "    return U1, V1, err_training, err_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LiI_vNVhi2h"
   },
   "source": [
    "#### Optimize eta for non-biase HW modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChnKH2atNTHW",
    "outputId": "0cdb0de0-bbbb-4943-f6db-24cc6ad7e67d"
   },
   "outputs": [],
   "source": [
    "def opt_non_bias_model(eta: float) -> float:\n",
    "\n",
    "    U1, V1, err_training, err_test = run_non_bias_model(\n",
    "        Y_train, M, N, Ks, eta\n",
    "    )\n",
    "\n",
    "    return err_test\n",
    "\n",
    "# Instrumentation class is used for functions with multiple inputs\n",
    "# (positional and/or keywords)\n",
    "\n",
    "Ks = 20\n",
    "\n",
    "# a greedy parametrization, we can reduce\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    eta=ng.p.Scalar(lower=0.01, upper=0.1),  # given 0.03\n",
    ")\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=10)\n",
    "recommendation = optimizer.minimize(opt_non_bias_model, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVrWESHni4Ie"
   },
   "source": [
    "#### Get UV, error, and plots with opt eta and reg for non-biased HW modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jH1spKBTjHi4",
    "outputId": "6dec210e-3b69-419f-9872-00e5cc275a98"
   },
   "outputs": [],
   "source": [
    " Ks = 20\n",
    " eta = 0.04851345326663499\n",
    " U1, V1, err_training, err_test = run_non_bias_model(Y_train, M, N, Ks, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "poJs3BhWi0g0",
    "outputId": "fe8058cd-924a-47be-dd08-c10eabf53418"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    U1_proj,\n",
    "    V1_proj,\n",
    "    comb_V1_df,\n",
    "    comb_U1_df,\n",
    "    counts_ecdf,\n",
    "    count_hist,\n",
    "    overlay_pt,\n",
    "    avg_hist_p,\n",
    "    rate_ecdf,\n",
    "    layout,\n",
    ") = get_UV2layout(\n",
    "    U1,\n",
    "    V1,\n",
    "    data,\n",
    "    movies,\n",
    "    three_genres,\n",
    "    rankcols,\n",
    "    \"without bias\",\n",
    "    ifhandpick=True,\n",
    "    chosen_id_dict=chosen_id_dict,\n",
    "    topn=10,\n",
    "    cutoff=5,\n",
    "    mostorleast=None,\n",
    "    xoff=0.2,\n",
    "    yoff=-0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjDna8TBNTln"
   },
   "source": [
    "### Surprise (No bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77HiIRtgjqxc"
   },
   "source": [
    "#### Optimize eta for non-biased with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKVtwHOMj84L",
    "outputId": "0075b471-68f6-46ae-d8d0-ba3bdb01aee2"
   },
   "outputs": [],
   "source": [
    "def optimize_non_bias_surprise(\n",
    "    n_factors: int, n_epochs: int, lr_all: float, \n",
    ") -> float:\n",
    "\n",
    "    \"\"\"n_factors – The number of factors. Default is 100.\n",
    "    n_epochs – The number of iteration of the SGD procedure. Default is 20.\n",
    "    biased (bool) – Whether to use baselines (or biases). See note above. Default is True.\n",
    "    init_mean – The mean of the normal distribution for factor vectors initialization. Default is 0.\n",
    "    init_std_dev – The standard deviation of the normal distribution for factor vectors initialization. Default is 0.1.\n",
    "    lr_all – The learning rate for all parameters. Default is 0.005.\n",
    "    reg_all – The regularization term for all parameters. Default is 0.02.\n",
    "    lr_bu – The learning rate for 𝑏𝑢. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_bi – The learning rate for 𝑏𝑖. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_pu – The learning rate for 𝑝𝑢. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_qi – The learning rate for 𝑞𝑖. Takes precedence over lr_all if set. Default is None.\n",
    "    reg_bu – The regularization term for 𝑏𝑢. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_bi – The regularization term for 𝑏𝑖. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_pu – The regularization term for 𝑝𝑢. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_qi – The regularization term for 𝑞𝑖. Takes precedence over reg_all if set. Default is None.\n",
    "    random_state (int, RandomState instance from numpy, or None) – \n",
    "    Determines the RNG that will be used for initialization. If int, random_state will be used as a seed for a new RNG. \n",
    "    This is useful to get the same initialization over multiple calls to fit(). \n",
    "    If RandomState instance, this same instance is used as RNG. \n",
    "    If None, the current RNG from numpy is used. Default is None.\n",
    "    verbose – If True, prints the current epoch. Default is False.\"\"\"\n",
    "\n",
    "    surprise_rmse, U, V = use_surprise(\n",
    "        Y_train_df,\n",
    "        n_factors,\n",
    "        n_epochs,\n",
    "        lr_all,\n",
    "        0,\n",
    "        ifbiased=False,\n",
    "        ifreg_bubi=False,\n",
    "    )\n",
    "    # Y_train_df, n_factors, n_epochs, lr_all, reg_all, ifbiased, ifreg_bubi\n",
    "    return surprise_rmse\n",
    "\n",
    "# Instrumentation class is used for functions with multiple inputs\n",
    "# (positional and/or keywords)\n",
    "\n",
    "# a greedy parametrization, we can reduce\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    n_factors=ng.p.Scalar(lower=50, upper=200).set_integer_casting(),\n",
    "    n_epochs=ng.p.Scalar(lower=10, upper=50).set_integer_casting(),\n",
    "    lr_all=ng.p.Scalar(lower=0.001, upper=0.1),\n",
    ")\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=10)\n",
    "recommendation = optimizer.minimize(optimize_non_bias_surprise, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DN6r19VPjza1"
   },
   "source": [
    "#### Get UV, error, and plots with opt eta for non-biased with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5ZiNozrkUb-",
    "outputId": "1be80f0b-c213-4fb6-ec64-cfde5ceaed5b"
   },
   "outputs": [],
   "source": [
    "n_factors = 149\n",
    "n_epochs = 31\n",
    "lr_all = 0.05832950360579468\n",
    "reg_all = 0\n",
    "\n",
    "surprise_rmse_notreg_bias, U4_proj, V4_proj  = use_surprise(\n",
    "        Y_train_df,\n",
    "        n_factors,\n",
    "        n_epochs,\n",
    "        lr_all,\n",
    "        reg_all,\n",
    "        ifbiased=False,\n",
    "        ifreg_bubi=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rTz2tthukYP-",
    "outputId": "6bfd44a7-4d7d-4978-8602-c0fd79b528aa"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    U4_proj,\n",
    "    V4_proj,\n",
    "    comb_V4_df,\n",
    "    comb_U4_df,\n",
    "    counts_ecdf,\n",
    "    count_hist,\n",
    "    overlay_pt,\n",
    "    avg_hist_p,\n",
    "    rate_ecdf,\n",
    "    layout,\n",
    ") = get_UV2layout(\n",
    "    U4_proj,\n",
    "    V4_proj,\n",
    "    data,\n",
    "    movies,\n",
    "    three_genres,\n",
    "    rankcols,\n",
    "    \"Suprise without bias\",\n",
    "    ifhandpick=True,\n",
    "    chosen_id_dict=chosen_id_dict,\n",
    "    topn=10,\n",
    "    cutoff=5,\n",
    "    mostorleast=None,\n",
    "    xoff=0,\n",
    "    yoff=-0.025,\n",
    "    needproj=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuc2QdaV74mk"
   },
   "source": [
    "## Method Two (Not regularized bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPrriu8qNhkt"
   },
   "source": [
    "### HW modification (Not regularized bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjA2dmzL8zuc"
   },
   "outputs": [],
   "source": [
    "def add_bias_UV(U, V):\n",
    "    \"\"\"Add biases to U and V\"\"\"\n",
    "    return (\n",
    "        np.hstack([np.ones((U.shape[0], 1)), U]),\n",
    "        np.vstack([np.ones((1, V.shape[1])), V]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoanjQjN8_Cl"
   },
   "outputs": [],
   "source": [
    "def train_nonreg_bias_model(M, N, K, eta, reg, Y, eps=0.0001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Modify the train_model function\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Initialize U, V  \n",
    "    U = np.random.random((M,K)) - 0.5\n",
    "    V = np.random.random((K,N)) - 0.5\n",
    "    \n",
    "    # Add bias\n",
    "    U, V = add_bias_UV(U, V)\n",
    "    \n",
    "    size = Y.shape[0]\n",
    "    delta = None\n",
    "    indices = np.arange(size)    \n",
    "    for epoch in range(max_epochs):\n",
    "        # Run an epoch of SGD\n",
    "        before_E_in = get_err(U, V, Y, reg)\n",
    "        np.random.shuffle(indices)\n",
    "        for ind in indices:\n",
    "            (i,j, Yij) = Y[ind]\n",
    "            # Update U[i], V[j]\n",
    "            U[i-1] = grad_U(U[i-1], Yij, V[:,j-1], reg, eta)\n",
    "            V[:,j-1] = grad_V(V[:,j-1], Yij, U[i-1], reg, eta);\n",
    "        # At end of epoch, print E_in\n",
    "        E_in = get_err(U, V, Y, reg)\n",
    "        print(\"Epoch %s, E_in (regularized MSE): %s\"%(epoch + 1, E_in))\n",
    "\n",
    "        # Compute change in E_in for first epoch\n",
    "        if epoch == 0:\n",
    "            delta = before_E_in - E_in\n",
    "\n",
    "        # If E_in doesn\"t decrease by some fraction <eps>\n",
    "        # of the initial decrease in E_in, stop early            \n",
    "        elif before_E_in - E_in < eps * delta:\n",
    "            break\n",
    "    return U, V, get_err(U, V, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNK0xqu29Dvh"
   },
   "outputs": [],
   "source": [
    "def run_nonreg_bias_model(M, N, Ks, eta, reg, Y_train, Y_test):\n",
    "    \"\"\"Run training with non-reg biase\"\"\"\n",
    "    # print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "    \n",
    "    U2, V2, err_training = train_nonreg_bias_model(M, N, Ks, eta, reg, Y_train)\n",
    "    err_test = get_err(U2, V2, Y_test)\n",
    "    \n",
    "    print(\"Err training\", err_training)\n",
    "    print(\"Err testing\", err_test)\n",
    "    # print(\"dim U [m x k]\", U2.shape)\n",
    "    # print(\"dim V [k x n]\", V2.shape)\n",
    "    \n",
    "    return U2, V2, err_training, err_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vie2VFPzY4q-"
   },
   "source": [
    "#### Optimize eta and reg for not regularized bias HW modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1DlVJBqR0Md",
    "outputId": "aa7b8626-d022-49f0-d3dc-9a64c0156b33"
   },
   "outputs": [],
   "source": [
    "def opt_nonreg_bias_model(eta: float, reg: float) -> float:\n",
    "\n",
    "    U2, V2, err_training, err_test = run_nonreg_bias_model(\n",
    "        M, N, Ks, eta, reg, Y_train, Y_test\n",
    "    )\n",
    "\n",
    "    return err_test\n",
    "\n",
    "\n",
    "# Instrumentation class is used for functions with multiple inputs\n",
    "# (positional and/or keywords)\n",
    "\n",
    "Ks = 20\n",
    "\n",
    "# a greedy parametrization, we can reduce\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    eta=ng.p.Scalar(lower=0.01, upper=0.1),  # given 0.03\n",
    "    reg=ng.p.Scalar(lower=0.01, upper=0.1),\n",
    ")\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=10)\n",
    "recommendation = optimizer.minimize(opt_nonreg_bias_model, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzEKvdcaVxlI"
   },
   "source": [
    "#### Get UV, error, and plots with opt eta and reg for not regularized bias HW modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYGCPy2ZVv7V",
    "outputId": "6906f662-f13d-4c7e-ec97-e8d7fd2a151e"
   },
   "outputs": [],
   "source": [
    "Ks = 20\n",
    "eta = 0.013227454444331396\n",
    "reg = 0.06917747048954087\n",
    "U2, V2, err_training, err_test = run_nonreg_bias_model(\n",
    "    M, N, Ks, eta, reg, Y_train, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-MpvFGw19mn3",
    "outputId": "cdfad1ba-af4c-455e-f27c-eb04e60d0a3c"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    U2_proj,\n",
    "    V2_proj,\n",
    "    comb_V2_df,\n",
    "    comb_U2_df,\n",
    "    counts_ecdf,\n",
    "    count_hist,\n",
    "    overlay_pt,\n",
    "    avg_hist_p,\n",
    "    rate_ecdf,\n",
    "    layout,\n",
    ") = get_UV2layout(\n",
    "    U2,\n",
    "    V2,\n",
    "    data,\n",
    "    movies,\n",
    "    three_genres,\n",
    "    rankcols,\n",
    "    \"with non-regularized bias\",\n",
    "    ifhandpick=True,\n",
    "    chosen_id_dict=chosen_id_dict,\n",
    "    topn=10,\n",
    "    cutoff=5,\n",
    "    mostorleast=None,\n",
    "    xoff=0.15,\n",
    "    yoff=-0.06\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGIUKz0RNbIM"
   },
   "source": [
    "### Surprise (Not regularized bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrARRtHodMih"
   },
   "source": [
    "#### Optimize eta and reg for not regularized bias with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdOp7-ONOtR9",
    "outputId": "d4508c7a-f94d-4124-ba71-e180390f48b5"
   },
   "outputs": [],
   "source": [
    "def optimize_nonreg_bias_surprise(\n",
    "    n_factors: int, n_epochs: int, lr_all: float, reg_all: int\n",
    ") -> float:\n",
    "\n",
    "    \"\"\"n_factors – The number of factors. Default is 100.\n",
    "    n_epochs – The number of iteration of the SGD procedure. Default is 20.\n",
    "    biased (bool) – Whether to use baselines (or biases). See note above. Default is True.\n",
    "    init_mean – The mean of the normal distribution for factor vectors initialization. Default is 0.\n",
    "    init_std_dev – The standard deviation of the normal distribution for factor vectors initialization. Default is 0.1.\n",
    "    lr_all – The learning rate for all parameters. Default is 0.005.\n",
    "    reg_all – The regularization term for all parameters. Default is 0.02.\n",
    "    lr_bu – The learning rate for 𝑏𝑢. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_bi – The learning rate for 𝑏𝑖. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_pu – The learning rate for 𝑝𝑢. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_qi – The learning rate for 𝑞𝑖. Takes precedence over lr_all if set. Default is None.\n",
    "    reg_bu – The regularization term for 𝑏𝑢. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_bi – The regularization term for 𝑏𝑖. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_pu – The regularization term for 𝑝𝑢. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_qi – The regularization term for 𝑞𝑖. Takes precedence over reg_all if set. Default is None.\n",
    "    random_state (int, RandomState instance from numpy, or None) – \n",
    "    Determines the RNG that will be used for initialization. If int, random_state will be used as a seed for a new RNG. \n",
    "    This is useful to get the same initialization over multiple calls to fit(). \n",
    "    If RandomState instance, this same instance is used as RNG. \n",
    "    If None, the current RNG from numpy is used. Default is None.\n",
    "    verbose – If True, prints the current epoch. Default is False.\"\"\"\n",
    "\n",
    "    surprise_rmse, U, V = use_surprise(\n",
    "        Y_train_df,\n",
    "        n_factors,\n",
    "        n_epochs,\n",
    "        lr_all,\n",
    "        reg_all,\n",
    "        ifbiased=True,\n",
    "        ifreg_bubi=False,\n",
    "    )\n",
    "    # Y_train_df, n_factors, n_epochs, lr_all, reg_all, ifbiased, ifreg_bubi\n",
    "    return surprise_rmse\n",
    "\n",
    "# Instrumentation class is used for functions with multiple inputs\n",
    "# (positional and/or keywords)\n",
    "\n",
    "# a greedy parametrization, we can reduce\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    n_factors=ng.p.Scalar(lower=50, upper=200).set_integer_casting(),\n",
    "    n_epochs=ng.p.Scalar(lower=10, upper=50).set_integer_casting(),\n",
    "    lr_all=ng.p.Scalar(lower=0.001, upper=0.1),\n",
    "    reg_all=ng.p.Scalar(lower=0.01, upper=0.1),\n",
    ")\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=10)\n",
    "recommendation = optimizer.minimize(optimize_nonreg_bias_surprise, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4XTI4a_dRxh"
   },
   "source": [
    "#### Get UV, error, and plots with opt eta and reg for not regularized bias with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pyd47rgBdUQs",
    "outputId": "437c789b-480b-4e21-ef80-1b04e8e07d8f"
   },
   "outputs": [],
   "source": [
    "n_factors = 125\n",
    "n_epochs = 35\n",
    "lr_all = 0.009813324125778348\n",
    "reg_all = 0.09073507141179653\n",
    "\n",
    "surprise_rmse_notreg_bias, U5_proj, V5_proj  = use_surprise(\n",
    "        Y_train_df,\n",
    "        n_factors,\n",
    "        n_epochs,\n",
    "        lr_all,\n",
    "        reg_all,\n",
    "        ifbiased=True,\n",
    "        ifreg_bubi=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gOTrT3A1eGcI",
    "outputId": "888cd6a7-068e-440a-f80f-483a3fcdc097"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    U5_proj,\n",
    "    V5_proj,\n",
    "    comb_V5_df,\n",
    "    comb_U5_df,\n",
    "    counts_ecdf,\n",
    "    count_hist,\n",
    "    overlay_pt,\n",
    "    avg_hist_p,\n",
    "    rate_ecdf,\n",
    "    layout,\n",
    ") = get_UV2layout(\n",
    "    U5_proj,\n",
    "    V5_proj,\n",
    "    data,\n",
    "    movies,\n",
    "    three_genres,\n",
    "    rankcols,\n",
    "    \"Suprise with non-regulated bias\",\n",
    "    ifhandpick=True,\n",
    "    chosen_id_dict=chosen_id_dict,\n",
    "    topn=10,\n",
    "    cutoff=5,\n",
    "    mostorleast=None,\n",
    "    xoff=0,\n",
    "    yoff=-0.025,\n",
    "    needproj=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYAICCmk7-E4"
   },
   "source": [
    "## Method Three (Regularized bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_reg_bias_model(M, N, Ks, eta, reg, Y_train, Y_test):\n",
    "    \"\"\"Run training with non-reg biase\"\"\"\n",
    "    # print(\"Factorizing with \", M, \" users, \", N, \" movies.\")\n",
    "\n",
    "    U3, V3, a, b, err_training = train_model_biased(\n",
    "        M, N, K, eta, reg, Y_train, eps=0.0001, max_epochs=300\n",
    "    )\n",
    "    err_test = get_err_biased(U3, V3, Y_test, a, b, reg)\n",
    "\n",
    "    print(\"Err training\", err_training)\n",
    "    print(\"Err testing\", err_test)\n",
    "\n",
    "    return U3, V3, err_training, err_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCh3owrI4eRE"
   },
   "source": [
    "### Surprise (Regularized bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP56_DtJ4h2-"
   },
   "source": [
    "#### Optimize eta and reg for regularized bias with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuvujDAN4fTj",
    "outputId": "b33d5388-9af0-4adb-8dd7-65b31d9bb44d"
   },
   "outputs": [],
   "source": [
    "def optimize_reg_bias_surprise(\n",
    "    n_factors: int, n_epochs: int, lr_all: float, reg_all: int\n",
    ") -> float:\n",
    "\n",
    "    \"\"\"n_factors – The number of factors. Default is 100.\n",
    "    n_epochs – The number of iteration of the SGD procedure. Default is 20.\n",
    "    biased (bool) – Whether to use baselines (or biases). See note above. Default is True.\n",
    "    init_mean – The mean of the normal distribution for factor vectors initialization. Default is 0.\n",
    "    init_std_dev – The standard deviation of the normal distribution for factor vectors initialization. Default is 0.1.\n",
    "    lr_all – The learning rate for all parameters. Default is 0.005.\n",
    "    reg_all – The regularization term for all parameters. Default is 0.02.\n",
    "    lr_bu – The learning rate for 𝑏𝑢. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_bi – The learning rate for 𝑏𝑖. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_pu – The learning rate for 𝑝𝑢. Takes precedence over lr_all if set. Default is None.\n",
    "    lr_qi – The learning rate for 𝑞𝑖. Takes precedence over lr_all if set. Default is None.\n",
    "    reg_bu – The regularization term for 𝑏𝑢. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_bi – The regularization term for 𝑏𝑖. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_pu – The regularization term for 𝑝𝑢. Takes precedence over reg_all if set. Default is None.\n",
    "    reg_qi – The regularization term for 𝑞𝑖. Takes precedence over reg_all if set. Default is None.\n",
    "    random_state (int, RandomState instance from numpy, or None) – \n",
    "    Determines the RNG that will be used for initialization. If int, random_state will be used as a seed for a new RNG. \n",
    "    This is useful to get the same initialization over multiple calls to fit(). \n",
    "    If RandomState instance, this same instance is used as RNG. \n",
    "    If None, the current RNG from numpy is used. Default is None.\n",
    "    verbose – If True, prints the current epoch. Default is False.\"\"\"\n",
    "\n",
    "    surprise_rmse, U, V = use_surprise(\n",
    "        Y_train_df,\n",
    "        n_factors,\n",
    "        n_epochs,\n",
    "        lr_all,\n",
    "        reg_all,\n",
    "        ifbiased=True,\n",
    "        ifreg_bubi=True,\n",
    "    )\n",
    "    # Y_train_df, n_factors, n_epochs, lr_all, reg_all, ifbiased, ifreg_bubi\n",
    "    return surprise_rmse\n",
    "\n",
    "# Instrumentation class is used for functions with multiple inputs\n",
    "# (positional and/or keywords)\n",
    "\n",
    "# a greedy parametrization, we can reduce\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    n_factors=ng.p.Scalar(lower=50, upper=200).set_integer_casting(),\n",
    "    n_epochs=ng.p.Scalar(lower=10, upper=50).set_integer_casting(),\n",
    "    lr_all=ng.p.Scalar(lower=0.001, upper=0.1),\n",
    "    reg_all=ng.p.Scalar(lower=0.01, upper=0.1),\n",
    ")\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=10)\n",
    "recommendation = optimizer.minimize(optimize_reg_bias_surprise, verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX9k82kA6XEf"
   },
   "source": [
    "#### Get UV, error, and plots with opt eta and reg for regularized bias with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urzQAkYR4u3G"
   },
   "outputs": [],
   "source": [
    "n_factors = 110\n",
    "n_epochs = 21\n",
    "lr_all = 0.029661498219795867\n",
    "reg_all = 0.050718435030741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGZq3VmJ6a5F",
    "outputId": "9f87b42e-70a2-4a65-8fa6-60ef1c9f81dd"
   },
   "outputs": [],
   "source": [
    "surprise_rmse_notreg_bias, U6_proj, V6_proj  = use_surprise(\n",
    "        Y_train_df,\n",
    "        n_factors,\n",
    "        n_epochs,\n",
    "        lr_all,\n",
    "        reg_all,\n",
    "        ifbiased=True,\n",
    "        ifreg_bubi=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yx5gTMEG6fGA",
    "outputId": "822bbced-3dfc-4104-a1bf-8762ac951f59"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    U6_proj,\n",
    "    V6_proj,\n",
    "    comb_V6_df,\n",
    "    comb_U6_df,\n",
    "    counts_ecdf,\n",
    "    count_hist,\n",
    "    overlay_pt,\n",
    "    avg_hist_p,\n",
    "    rate_ecdf,\n",
    "    layout,\n",
    ") = get_UV2layout(\n",
    "    U6_proj,\n",
    "    V6_proj,\n",
    "    data,\n",
    "    movies,\n",
    "    three_genres,\n",
    "    rankcols,\n",
    "    \"Suprise with non-regulated bias\",\n",
    "    ifhandpick=True,\n",
    "    chosen_id_dict=chosen_id_dict,\n",
    "    topn=10,\n",
    "    cutoff=5,\n",
    "    mostorleast=None,\n",
    "    xoff=0,\n",
    "    yoff=-0.025,\n",
    "    needproj=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas_project2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
