{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    data_txt = open('data/shakespeare.txt')\n",
    "    quatrain = []; volta = []; couplet = [];\n",
    "    \n",
    "    Lines = data_txt.readlines()\n",
    "    count=0\n",
    "    for i,line in enumerate(Lines):\n",
    "        if any(char.isdigit() for char in line):\n",
    "            for j in range(1,9):\n",
    "                quatrain.append(Lines[i+j][:-1])\n",
    "            for j in range(9,13):\n",
    "                volta.append(Lines[i+j][:-1])\n",
    "            for j in range(13,15):\n",
    "                couplet.append(Lines[i+j][:-1])\n",
    "    return quatrain,volta,couplet\n",
    "\n",
    "\n",
    "def load_key(includePunctuation=True):\n",
    "    \n",
    "    data_key = open('data/Syllable_dictionary.txt')\n",
    "    Lines = data_key.readlines()\n",
    "    \n",
    "    key_list = [];\n",
    "    \n",
    "    for i,line in enumerate(Lines):\n",
    "        split_str = line.strip(punctuation).split()\n",
    "        if len(split_str) == 3:\n",
    "            if len(split_str[1])==2:\n",
    "                key_list.append([split_str[0],[int(split_str[2])],int(split_str[1][1])])\n",
    "            elif len(split_str[2])==2:\n",
    "                key_list.append([split_str[0],[int(split_str[1])],int(split_str[2][1])])\n",
    "            else:\n",
    "                key_list.append([split_str[0],[int(split_str[1]),int(split_str[2])],0])\n",
    "\n",
    "        else:\n",
    "            key_list.append([split_str[0],[int(split_str[1])],0])\n",
    "    \n",
    "    #append punctuation\n",
    "    if includePunctuation==True:\n",
    "        #comma\n",
    "        key_list.append([',',[0],0])\n",
    "        #period\n",
    "        key_list.append(['.',[0],0])\n",
    "        #question\n",
    "        key_list.append(['?',[0],0])\n",
    "        #colon\n",
    "        key_list.append([':',[0],0])\n",
    "        #semicolon\n",
    "        key_list.append([';',[0],0])\n",
    "    \n",
    "    return key_list\n",
    "    \n",
    "    \n",
    "    \n",
    "def convert_to_nums(dataset,key_list,includePunctuation=True):\n",
    "    punc_list = [',','.','?',':',';']\n",
    "    word_list = [i[0] for i in key_list]\n",
    "    seq_list = []\n",
    "    for i in range(0,len(dataset)):\n",
    "        words = dataset[i].split()\n",
    "        seq = []\n",
    "        for j in range(0,len(words)):\n",
    "            if words[j].lower() == \"th'\" or words[j].lower() == \"t'\":\n",
    "                n = word_list.index(words[j].lower())\n",
    "            else:\n",
    "                n = word_list.index(words[j].lower().strip(punctuation))\n",
    "            seq.append(n)\n",
    "            \n",
    "            if includePunctuation==True:\n",
    "                if words[j][-1] in punc_list:\n",
    "                    seq.append(word_list.index(words[j][-1]))\n",
    "            \n",
    "        seq_list.append(seq)\n",
    "    \n",
    "    return seq_list\n",
    "\n",
    "def convert_to_nums_red_keylist(dataset,key_list,includePunctuation=True):\n",
    "    punc_list = [',','.','?',':',';']\n",
    "    word_list = [i[0] for i in key_list]\n",
    "    seq_list = []\n",
    "    \n",
    "    key_list_red = []\n",
    "    used_inds = []\n",
    "    for i in range(0,len(dataset)):\n",
    "        words = dataset[i].split()\n",
    "        seq = []\n",
    "        for j in range(0,len(words)):\n",
    "            if words[j].lower() == \"th'\" or words[j].lower() == \"t'\":\n",
    "                n = word_list.index(words[j].lower())\n",
    "            else:\n",
    "                n = word_list.index(words[j].lower().strip(punctuation))\n",
    "            if n not in used_inds:\n",
    "                used_inds.append(n)\n",
    "                key_list_red.append(key_list[n])\n",
    "                \n",
    "            seq.append(n)    \n",
    "            if includePunctuation==True:\n",
    "                if words[j][-1] in punc_list:\n",
    "                    punc_indx = word_list.index(words[j][-1])\n",
    "                    seq.append(punc_indx)\n",
    "                    if punc_indx not in used_inds:\n",
    "                        used_inds.append(punc_indx)\n",
    "                        key_list_red.append(key_list[punc_indx])\n",
    "        seq_list.append(seq)\n",
    "    \n",
    "    #convert sequence to 'reduced' indices\n",
    "    seq_list_red = []\n",
    "    for i in range(0,len(seq_list)):\n",
    "        seq_list_red_cur = []\n",
    "        for j in range(0,len(seq_list[i])):\n",
    "            seq_list_red_cur.append(used_inds.index(seq_list[i][j]))\n",
    "        seq_list_red.append(seq_list_red_cur)\n",
    "    \n",
    "    \n",
    "    return seq_list_red,key_list_red\n",
    "\n",
    "def generate_sequences():\n",
    "    #CALL THIS TO GENERATE THE 3 TRAINING DATASETS\n",
    "    #OUTPUTS:\n",
    "    #seq_list_quatrain: list of sequences corresponding to lines in the first 2 quatrains\n",
    "    #seq_list_volta: list of sequences corresponding to lines in the volta\n",
    "    #seq_list_couplet: list of sequences corresponding to lines in the couplet\n",
    "    #key_list: list of lists containing information stored in Syllable_dictionary:\n",
    "    #Each list corresponds to a word, with index 0 being the word, \n",
    "    #index 1 being a list containing possible numbers of syllables, and index 2 being the number of syllables if it's\n",
    "    #an end word.\n",
    "    \n",
    "    quatrain,volta,couplet = load_data()\n",
    "    key_list = load_key()\n",
    "    seq_list_quatrain = convert_to_nums(quatrain,key_list)\n",
    "    seq_list_volta = convert_to_nums(volta,key_list)\n",
    "    seq_list_couplet = convert_to_nums(couplet,key_list)\n",
    "    return seq_list_quatrain,seq_list_volta,seq_list_couplet,key_list\n",
    "\n",
    "def generate_sequences_reduced(includePunctuation = True):\n",
    "    #CALL THIS TO GENERATE THE 3 TRAINING DATASETS\n",
    "    #OUTPUTS:\n",
    "    #seq_lists: list with 3 elements corresponding to the 3 lists of sequences\n",
    "    #key_lists: list with 3 elements corresponding to the 3 associated key lists\n",
    "    \n",
    "    quatrain,volta,couplet = load_data()\n",
    "    key_list = load_key(includePunctuation)\n",
    "    \n",
    "    seq_list_quatrain,key_list_quatrain = convert_to_nums_red_keylist(quatrain,key_list,includePunctuation)\n",
    "    seq_list_volta,key_list_volta = convert_to_nums_red_keylist(volta,key_list,includePunctuation)\n",
    "    seq_list_couplet,key_list_couplet = convert_to_nums_red_keylist(couplet,key_list,includePunctuation)\n",
    "    \n",
    "    seq_lists = [seq_list_quatrain,seq_list_volta,seq_list_couplet]\n",
    "    key_lists = [key_list_quatrain,key_list_volta,key_list_couplet]\n",
    "    return seq_lists,key_lists\n",
    "\n",
    "def generate_rhyme_lists():\n",
    "    #Returns 3 lists of rhymes, one for quatrain, volta, couplet\n",
    "    \n",
    "    key_list = load_key(includePunctuation=False)\n",
    "    seq_lists,key_lists = generate_sequences_reduced(includePunctuation=False)\n",
    "    rhymes = get_rhymes(seq_lists)\n",
    "    \n",
    "    rhyme_list_quatrain = [];\n",
    "    rhyme_list_volta = [];\n",
    "    rhyme_list_couplet = [];\n",
    "    for i in range(0,len(rhymes[0])):\n",
    "        rhyme_list_quatrain.append([key_lists[0][rhymes[0][i][0]][0],key_lists[0][rhymes[0][i][1]][0]])\n",
    "    for i in range(0,len(rhymes[1])):\n",
    "        rhyme_list_volta.append([key_lists[1][rhymes[1][i][0]][0],key_lists[1][rhymes[1][i][1]][0]])\n",
    "    for i in range(0,len(rhymes[2])):\n",
    "        rhyme_list_couplet.append([key_lists[2][rhymes[2][i][0]][0],key_lists[2][rhymes[2][i][1]][0]])\n",
    "    \n",
    "    return [rhyme_list_quatrain,rhyme_list_volta,rhyme_list_couplet]\n",
    "\n",
    "def get_rhymes(seq_lists):\n",
    "    #requires sequence lists with no punctuation\n",
    "    rhyme_list_quatrain = []\n",
    "    for i in range(0,len(seq_lists[0])-2,4):\n",
    "        add_rhyme([seq_lists[0][i][-1],seq_lists[0][i+2][-1]],rhyme_list_quatrain)\n",
    "        add_rhyme([seq_lists[0][i+1][-1],seq_lists[0][i+3][-1]],rhyme_list_quatrain)\n",
    "    rhyme_list_volta = []\n",
    "    for i in range(0,len(seq_lists[1])-2,4):\n",
    "        add_rhyme([seq_lists[1][i][-1],seq_lists[1][i+2][-1]],rhyme_list_volta)\n",
    "        add_rhyme([seq_lists[1][i+1][-1],seq_lists[1][i+3][-1]],rhyme_list_volta)\n",
    "    rhyme_list_couplet = []\n",
    "\n",
    "    for i in range(0,len(seq_lists[2])-1,2):\n",
    "        if seq_lists[2][i] and seq_lists[2][i+1]:\n",
    "            add_rhyme([seq_lists[2][i][-1],seq_lists[2][i+1][-1]],rhyme_list_couplet)\n",
    "    \n",
    "    return [rhyme_list_quatrain,rhyme_list_volta,rhyme_list_couplet]\n",
    "               \n",
    "            \n",
    "def add_rhyme(rhyme,rhyme_list):\n",
    "    if rhyme not in rhyme_list and [rhyme[1],rhyme[0]] not in rhyme_list:\n",
    "        rhyme_list.append(rhyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ornament', 'content'], ['spring', 'niggarding'], ['use', 'excuse'], ['mine', 'thine'], ['thee', 'see'], ['prime', 'time'], ['alone', 'gone'], ['deceive', 'leave'], ['left', 'bereft'], ['glass', 'was'], ['art', 'depart'], ['thee', 'posterity'], ['car', 'are'], ['day', 'way'], ['another', 'mother'], ['ordering', 'sing'], ['spend', 'end'], ['it', 'it'], ['mind', 'kind'], ['love', 'prove'], ['store', 'more'], ['perish', 'cherish'], ['make', 'forsake'], ['go', 'grow'], ['decay', 'day'], ['uphold', 'cold'], ['derive', 'thrive'], ['art', 'convert'], ['stay', 'decay'], ['sight', 'night'], ['repair', 'fair'], ['pen', 'men'], ['age', 'rage'], ['tongue', 'song'], ['fade', 'shade'], [\"ow'st\", \"grow'st\"], ['brow', 'allow'], ['created', 'defeated'], ['a-doting', 'nothing'], ['write', 'bright'], ['fair', 'air'], ['wary', 'chary'], ['will', 'ill'], ['eloquence', 'recompense'], ['breast', 'expressed'], ['done', 'sun'], ['me', 'thee'], ['fight', 'quite'], ['foiled', 'toiled'], ['moving', 'loving'], ['aspect', 'respect'], ['view', 'new'], ['bright', 'night'], ['heaven', 'even'], ['despising', 'arising'], ['state', 'gate'], ['foregone', 'moan'], [\"o'er\", 'before'], ['live', 'give'], ['thought', 'brought'], ['age', 'equipage'], ['shine', 'mine'], ['brow', 'now'], ['grief', 'relief'], ['loss', 'cross'], ['sense', 'commence'], ['advocate', 'hate'], ['shame', 'name'], ['despised', 'sufficed'], ['worth', 'forth'], ['invocate', 'date'], ['thief', 'grief'], ['poverty', 'injury'], ['forbear', 'there'], ['youth', 'truth'], ['gain', 'twain'], ['made', 'shade'], ['day', 'stay'], ['thought', 'wrought'], ['gone', 'moan'], ['recured', 'assured'], ['impanelled', 'determined'], ['heart', 'part'], ['love', 'move'], ['chest', 'breast'], ['art', 'part'], ['here', 'uprear'], ['desert', 'part'], ['on', 'groan'], ['hide', 'side'], ['pace', 'race'], ['made', 'jade'], ['chest', 'special-blest'], ['hide', 'pride'], ['year', 'appear'], ['show', 'know'], ['show', 'so'], ['fade', 'made'], ['enmity', 'posterity'], ['room', 'doom'], ['be', 'see'], ['thought', 'nought'], ['suppose', 'those'], ['strong', 'belong'], ['time', 'crime'], ['say', 'they'], ['frame', 'same'], ['brow', 'mow'], ['great', 'defeat'], ['awake', 'sake'], ['indeed', 'read'], ['antiquity', 'iniquity'], ['fortify', 'memory'], ['knife', 'life'], ['state', 'ruminate'], ['decay', 'away'], ['alack', 'back'], ['hid', 'forbid'], ['authority', 'simplicity'], ['skill', 'ill'], ['is', 'his'], ['veins', 'gains'], ['seen', 'green'], ['true', 'new'], ['deeds', 'weeds'], ['days', 'praise'], ['charged', 'enlarged'], ['verse', 'rehearse'], ['clay', 'decay'], ['this', 'is'], ['untrue', 'you'], ['fire', 'expire'], ['lie', 'by'], ['dead', 'remembered'], ['sight', 'delight'], ['look', 'took'], ['you', 'new'], ['argument', 'spent'], ['contain', 'brain'], ['find', 'mind'], ['compile', 'style'], ['thee', 'be'], ['word', 'afford'], ['afloat', 'boat'], ['ride', 'pride'], [\"o'er-read\", 'dead'], ['devised', 'sympathized'], ['lend', 'friend'], ['impute', 'mute'], ['dumb', 'tomb'], ['writ', 'wit'], ['clear', 'where'], ['true', 'you'], ['more', 'before'], ['ghost', 'boast'], ['intelligence', 'thence'], ['knowing', 'growing'], ['mistaking', 'making'], ['too', 'do'], ['tongue', 'wronk'], ['dwell', 'tell'], ['last', 'taste'], ['spite', 'might'], ['me', 'be'], ['costs', 'boast'], ['lie', 'die'], ['decree', 'be'], ['sweet', 'meet'], ['die', 'dignity'], ['got', 'blot'], ['betray', 'away'], ['translate', 'state'], ['fruit', 'mute'], ['white', 'delight'], ['rose', 'those'], ['despair', 'breath'], ['both', 'growth'], ['survey', 'decay'], ['there', 'everywhere'], ['now', 'bough'], ['night', 'delight'], ['mend', 'tend'], ['well', 'tell'], ['hand', 'stand'], ['perceived', 'deceived'], ['words', 'affords'], ['prophecies', 'eyes'], ['prefiguring', 'sing'], ['time', 'rhyme'], ['subscribes', 'tribes'], ['case', 'place'], ['age', 'page'], ['reigned', 'stained'], ['blood', 'good'], ['end', 'friend'], ['grind', 'confined'], ['drink', 'think'], ['infection', 'correction'], ['care', 'are'], ['sense', 'dispense'], ['creature', 'feature'], ['seeing', 'greeing'], ['up', 'cup'], ['tyranny', 'incertainty'], ['best', 'rest'], ['cheeks', 'weeks'], ['come', 'doom'], ['down', 'frown'], ['accumulate', 'hate'], ['anticipate', 'state'], ['assured', 'cured'], ['true', 'anew'], ['better', 'greater'], ['remembered', 'tendered'], ['hits', 'fits'], ['level', 'bevel'], ['own', 'shown'], ['hold', 'bold'], ['score', 'more'], ['defy', 'lie'], ['past', 'haste'], ['heretic', 'politic'], ['hours', 'showers'], ['heart', 'art'], ['free', 'thee'], ['pleasure', 'be'], ['treasure', 'thee'], ['black', 'lack'], ['seem', 'esteem'], ['state', 'gait'], ['chips', 'lips'], ['so', 'woe'], ['extreme', 'dream'], ['know', 'go'], ['sound', 'ground'], ['swear', 'bear'], ['face', 'place'], ['face', 'grace'], ['ward', 'guard'], ['bail', 'gaol'], ['take', 'sake'], ['use', 'abuse'], ['still', 'will'], ['untold', 'hold'], ['plot', 'not'], ['unjust', 'trust'], ['old', 'told'], ['knows', 'foes'], ['enemies', 'injuries'], ['mad', 'bad'], ['can', 'man'], ['those', 'grows'], ['behind', 'kind'], ['fiend', 'friend'], ['tell', 'hell'], ['end', 'fiend'], ['day', 'away'], ['loss', 'dross'], ['unrest', 'expressed'], ['true', 'view'], ['tears', 'clears'], ['respect', 'defect'], ['despise', 'eyes'], ['more', 'abhor'], ['hate', 'state'], ['pride', 'side'], ['kindness', 'blindness'], ['constancy', 'see'], ['new-fired', 'desired'], ['breast', 'guest'], ['by', 'remedy'], ['perpetual', 'thrall']]\n"
     ]
    }
   ],
   "source": [
    "quatrain,volta,couplet = load_data()\n",
    "key_list = load_key(includePunctuation=False)\n",
    "\n",
    "#seq_list = convert_to_nums(quatrain,key_list)\n",
    "seq_lists,key_lists = generate_sequences_reduced(includePunctuation=False)\n",
    "rhymes = get_rhymes(seq_lists)\n",
    "rhyme_words = generate_rhyme_lists()\n",
    "# for i in range(0,len(rhymes[0])):\n",
    "#     print(key_lists[0][rhymes[0][i][0]][0]+' '+key_lists[0][rhymes[0][i][1]][0]+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
